{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8baa6aed",
   "metadata": {},
   "source": [
    "# 3D CNN to predict the antidepressant effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd0eca",
   "metadata": {},
   "source": [
    "Import and check dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ab6236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n",
      "PyTorch version 2.5.1\n",
      "Numpy version 1.26.4\n",
      "Pandas version 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0128d25e",
   "metadata": {},
   "source": [
    "Check CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a80831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Device count: 1\n",
      "Device name: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "# Confirm device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "try: \n",
    "    name = torch.cuda.get_device_name(0)\n",
    "    count = torch.cuda.device_count()\n",
    "    print(f\"Device count: {count}\")\n",
    "    print(f\"Device name: {name}\")\n",
    "except RuntimeError:\n",
    "    print('No GPUs detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759bd18",
   "metadata": {},
   "source": [
    "Load the test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e8da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X_train = np.load('data/X_TRAIN_RAW.npy')\n",
    "X_test = np.load('data/X_TEST_RAW.npy')\n",
    "\n",
    "# Load labels\n",
    "y_train = np.load('data/y_TRAIN_RAW.npy')\n",
    "y_test = np.load('data/y_TEST_RAW.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe66cb",
   "metadata": {},
   "source": [
    "Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312c2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "class COPEDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get the data and label\n",
    "        cope_data = self.data[index]\n",
    "        label = self.target[index]\n",
    "\n",
    "        # Normalize the data thorugh per-subject z-score normalization\n",
    "        cope_data = (cope_data - np.mean(cope_data)) / np.std(cope_data)\n",
    "\n",
    "        # Convert to tensors\n",
    "        volume = torch.tensor(cope_data, dtype=torch.float32).unsqueeze(0)  # (1, 91, 109, 91) expects # of chanennels first\n",
    "        label = torch.tensor([1.0, 0.0] if label == 0 else [0.0, 1.0], dtype=torch.float32)\n",
    "\n",
    "        return volume, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3f8c3",
   "metadata": {},
   "source": [
    "Initiate the dataset and the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6a6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the dataset\n",
    "train_dataset = COPEDataset(X_train, y_train)\n",
    "test_dataset = COPEDataset(X_test, y_test)\n",
    "\n",
    "# Initiate dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6accce62",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8754d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class BrainClassifier3D(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BrainClassifier3D, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Calculate the size of the flattened layer dynamically\n",
    "        # Run a dummy tensor through the conv/pool layers to find the shape\n",
    "        self._to_linear = None\n",
    "        dummy_tesnor_shape = (1, 91, 109, 91) # Input shape (C, D, H))\n",
    "        self._get_conv_output(dummy_tesnor_shape)\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self._to_linear, 1280),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1280, 256),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),   # Optional dropout layer\n",
    "            nn.Linear(256, 2),  # 2 output classes\n",
    "            #nn.Softmax(dim=0)  # Optional softmax layer (not needed with CrossEntropyLoss)\n",
    "        )\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        \"\"\"\n",
    "        Helper function to calculate the input size for the fully connected layers.\n",
    "        \n",
    "        Args:\n",
    "            shape (tuple): The shape of the input tensor (C, D, H,).\n",
    "        Returns:\n",
    "            None: Sets the self._to_linear attribute.\n",
    "        \"\"\"\n",
    "        # Create a dummy input tensor with batch size 1\n",
    "        dummy_input = torch.rand(1, *shape) \n",
    "        output_features = self.conv_layers(dummy_input)\n",
    "        # Store the calculated size\n",
    "        self._to_linear = output_features.view(output_features.size(0), -1).size(1)\n",
    "        print(f\"Calculated flattened feature size: {self._to_linear}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x  # logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57d33a",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43cbb035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated flattened feature size: 9216\n",
      "Epoch 1, Loss: 400.50, Accuracy: 0.5676\n",
      "Epoch 2, Loss: 37.46, Accuracy: 0.6216\n",
      "Epoch 3, Loss: 27.89, Accuracy: 0.5946\n",
      "Epoch 4, Loss: 28.16, Accuracy: 0.5405\n",
      "Epoch 5, Loss: 33.52, Accuracy: 0.5676\n",
      "Epoch 6, Loss: 27.84, Accuracy: 0.4865\n",
      "Epoch 7, Loss: 23.93, Accuracy: 0.4595\n",
      "Epoch 8, Loss: 22.57, Accuracy: 0.4865\n",
      "Epoch 9, Loss: 21.66, Accuracy: 0.5676\n",
      "Epoch 10, Loss: 20.73, Accuracy: 0.6486\n",
      "Epoch 11, Loss: 18.74, Accuracy: 0.7027\n",
      "Epoch 12, Loss: 19.87, Accuracy: 0.7297\n",
      "Epoch 13, Loss: 23.21, Accuracy: 0.7297\n",
      "Epoch 14, Loss: 30.88, Accuracy: 0.7027\n",
      "Epoch 15, Loss: 19.70, Accuracy: 0.7568\n",
      "Epoch 16, Loss: 12.92, Accuracy: 0.8649\n",
      "Epoch 17, Loss: 10.86, Accuracy: 0.9189\n",
      "Epoch 18, Loss: 2.83, Accuracy: 0.9730\n",
      "Epoch 19, Loss: 5.14, Accuracy: 0.9459\n",
      "Epoch 20, Loss: 0.11, Accuracy: 1.0000\n",
      "Epoch 21, Loss: 0.05, Accuracy: 1.0000\n",
      "Epoch 22, Loss: 0.02, Accuracy: 1.0000\n",
      "Epoch 23, Loss: 0.01, Accuracy: 1.0000\n",
      "Epoch 24, Loss: 0.00, Accuracy: 1.0000\n",
      "Epoch 25, Loss: 0.00, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "model = BrainClassifier3D().cuda()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 25\n",
    "\n",
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "    acc = correct / len(train_dataloader.dataset)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.2f}, Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8466257",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4aaa6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0   True: 0\n",
      "Predicted: 0   True: 0\n",
      "Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    preds_list = np.array([])\n",
    "    actual_list = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1) # Sign inversion for uknown reason\n",
    "            preds_list = np.append(preds_list, preds.item())\n",
    "            actual_list = np.append(actual_list, torch.argmax(labels, dim=1).item())\n",
    "            print(f'Predicted: {preds.item()}   True: {torch.argmax(labels, dim=1).item()}')\n",
    "            correct += (preds == torch.argmax(labels, dim=1)).sum().item()\n",
    "    return correct / len(dataloader.dataset), preds_list, actual_list\n",
    "\n",
    "val_acc, preds_list, actual_list = evaluate(model, test_dataloader)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1778ce",
   "metadata": {},
   "source": [
    "Output test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a8b21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(actual_list, preds_list)\n\u001b[1;32m      2\u001b[0m matrix \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWR\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBlues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py:185\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw, text_kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m colorbar:\n\u001b[1;32m    184\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[0;32m--> 185\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim((n_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m    195\u001b[0m plt\u001b[38;5;241m.\u001b[39msetp(ax\u001b[38;5;241m.\u001b[39mget_xticklabels(), rotation\u001b[38;5;241m=\u001b[39mxticks_rotation)\n",
      "File \u001b[0;32m/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/matplotlib/artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mArtist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/matplotlib/artist.py:1224\u001b[0m, in \u001b[0;36mArtist.set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/matplotlib/artist.py:1216\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/matplotlib/artist.py:1192\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m   1190\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1191\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[0;32m-> 1192\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpchanged()\n",
      "File \u001b[0;32m/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/matplotlib/axes/_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orcd/software/core/001/pkg/miniforge/24.3.0-0/lib/python3.10/site-packages/matplotlib/axis.py:2071\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   2068\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2071\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2073\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2076\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[1;32m   2077\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (2)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(actual_list, preds_list)\n",
    "matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['SD', 'WR'])\n",
    "matrix.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
